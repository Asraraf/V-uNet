{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5iG8ilHoEQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib.framework.python.ops import arg_scope\n",
        "import nn\n",
        "\n",
        "\n",
        "def model_arg_scope(**kwargs):\n",
        "    \"\"\"Create new counter and apply arg scope to all arg scoped nn\n",
        "    operations.\"\"\"\n",
        "    counters = {}\n",
        "    return arg_scope(\n",
        "            [nn.conv2d, nn.deconv2d, nn.residual_block, nn.dense, nn.activate],\n",
        "            counters = counters, **kwargs)\n",
        "\n",
        "\n",
        "def make_model(name, template, **kwargs):\n",
        "    \"\"\"Create model with fixed kwargs.\"\"\"\n",
        "    run = lambda *args, **kw: template(*args, **dict((k, v) for kws in (kw, kwargs) for k, v in kws.items()))\n",
        "    return tf.make_template(name, run, unique_name_ = name)\n",
        "\n",
        "\n",
        "def dec_up(\n",
        "        c, init = False, dropout_p = 0.5,\n",
        "        n_scales = 1, n_residual_blocks = 2, activation = \"elu\", n_filters = 64, max_filters = 128):\n",
        "    with model_arg_scope(\n",
        "            init = init, dropout_p = dropout_p, activation = activation):\n",
        "        # outputs\n",
        "        hs = []\n",
        "        # prepare input\n",
        "        h = nn.nin(c, n_filters)\n",
        "        for l in range(n_scales):\n",
        "            # level module\n",
        "            for i in range(n_residual_blocks):\n",
        "                h = nn.residual_block(h)\n",
        "                hs.append(h)\n",
        "            # prepare input to next level\n",
        "            if l + 1 < n_scales:\n",
        "                n_filters = min(2*n_filters, max_filters)\n",
        "                h = nn.downsample(h, n_filters)\n",
        "        return hs\n",
        "\n",
        "\n",
        "def dec_down(\n",
        "        gs, zs_posterior, training, init = False, dropout_p = 0.5,\n",
        "        n_scales = 1, n_residual_blocks = 2, activation = \"elu\",\n",
        "        n_latent_scales = 2):\n",
        "    assert n_residual_blocks % 2 == 0\n",
        "    gs = list(gs)\n",
        "    zs_posterior = list(zs_posterior)\n",
        "    with model_arg_scope(\n",
        "            init = init, dropout_p = dropout_p, activation = activation):\n",
        "        # outputs\n",
        "        hs = [] # hidden units\n",
        "        ps = [] # priors\n",
        "        zs = [] # prior samples\n",
        "        # prepare input\n",
        "        n_filters = gs[-1].shape.as_list()[-1]\n",
        "        h = nn.nin(gs[-1], n_filters)\n",
        "        for l in range(n_scales):\n",
        "            # level module\n",
        "            ## hidden units\n",
        "            for i in range(n_residual_blocks // 2):\n",
        "                h = nn.residual_block(h, gs.pop())\n",
        "                hs.append(h)\n",
        "            if l < n_latent_scales:\n",
        "                ## prior\n",
        "                spatial_shape = h.shape.as_list()[1]\n",
        "                n_h_channels = h.shape.as_list()[-1]\n",
        "                if spatial_shape == 1:\n",
        "                    ### no spatial correlations\n",
        "                    p = latent_parameters(h)\n",
        "                    ps.append(p)\n",
        "                    z_prior = latent_sample(p)\n",
        "                    zs.append(z_prior)\n",
        "                else:\n",
        "                    ### four autoregressively modeled groups\n",
        "                    if training:\n",
        "                        z_posterior_groups = nn.split_groups(zs_posterior[0])\n",
        "                    p_groups = []\n",
        "                    z_groups = []\n",
        "                    p_features = tf.space_to_depth(nn.residual_block(h), 2)\n",
        "                    for i in range(4):\n",
        "                        p_group = latent_parameters(p_features, num_filters = n_h_channels)\n",
        "                        p_groups.append(p_group)\n",
        "                        z_group = latent_sample(p_group)\n",
        "                        z_groups.append(z_group)\n",
        "                        # ar feedback sampled from\n",
        "                        if training:\n",
        "                            feedback = z_posterior_groups.pop(0)\n",
        "                        else:\n",
        "                            feedback = z_group\n",
        "                        # prepare input for next group\n",
        "                        if i + 1 < 4:\n",
        "                            p_features = nn.residual_block(p_features, feedback)\n",
        "                    if training:\n",
        "                        assert not z_posterior_groups\n",
        "                    # complete prior parameters\n",
        "                    p = nn.merge_groups(p_groups)\n",
        "                    ps.append(p)\n",
        "                    # complete prior sample\n",
        "                    z_prior = nn.merge_groups(z_groups)\n",
        "                    zs.append(z_prior)\n",
        "                ## vae feedback sampled from\n",
        "                if training:\n",
        "                    ## posterior\n",
        "                    z = zs_posterior.pop(0)\n",
        "                else:\n",
        "                    ## prior\n",
        "                    z = z_prior\n",
        "                for i in range(n_residual_blocks // 2):\n",
        "                    n_h_channels = h.shape.as_list()[-1]\n",
        "                    h = tf.concat([h, z], axis = -1)\n",
        "                    h = nn.nin(h, n_h_channels)\n",
        "                    h = nn.residual_block(h, gs.pop())\n",
        "                    hs.append(h)\n",
        "            else:\n",
        "                for i in range(n_residual_blocks // 2):\n",
        "                    h = nn.residual_block(h, gs.pop())\n",
        "                    hs.append(h)\n",
        "            # prepare input to next level\n",
        "            if l + 1 < n_scales:\n",
        "                n_filters = gs[-1].shape.as_list()[-1]\n",
        "                h = nn.upsample(h, n_filters)\n",
        "\n",
        "        assert not gs\n",
        "        if training:\n",
        "            assert not zs_posterior\n",
        "\n",
        "        return hs, ps, zs\n",
        "\n",
        "\n",
        "def enc_up(\n",
        "        x, c, init = False, dropout_p = 0.5,\n",
        "        n_scales = 1, n_residual_blocks = 2, activation = \"elu\", n_filters = 64, max_filters = 128):\n",
        "    with model_arg_scope(\n",
        "            init = init, dropout_p = dropout_p, activation = activation):\n",
        "        # outputs\n",
        "        hs = []\n",
        "        # prepare input\n",
        "        #xc = tf.concat([x,c], axis = -1)\n",
        "        xc = x\n",
        "        h = nn.nin(xc, n_filters)\n",
        "        for l in range(n_scales):\n",
        "            # level module\n",
        "            for i in range(n_residual_blocks):\n",
        "                h = nn.residual_block(h)\n",
        "                hs.append(h)\n",
        "            # prepare input to next level\n",
        "            if l + 1 < n_scales:\n",
        "                n_filters = min(2*n_filters, max_filters)\n",
        "                h = nn.downsample(h, n_filters)\n",
        "        return hs\n",
        "\n",
        "\n",
        "def enc_down(\n",
        "        gs, init = False, dropout_p = 0.5,\n",
        "        n_scales = 1, n_residual_blocks = 2, activation = \"elu\",\n",
        "        n_latent_scales = 2):\n",
        "    assert n_residual_blocks % 2 == 0\n",
        "    gs = list(gs)\n",
        "    with model_arg_scope(\n",
        "            init = init, dropout_p = dropout_p, activation = activation):\n",
        "        # outputs\n",
        "        hs = [] # hidden units\n",
        "        qs = [] # posteriors\n",
        "        zs = [] # samples from posterior\n",
        "        # prepare input\n",
        "        n_filters = gs[-1].shape.as_list()[-1]\n",
        "        h = nn.nin(gs[-1], n_filters)\n",
        "        for l in range(n_scales):\n",
        "            # level module\n",
        "            ## hidden units\n",
        "            for i in range(n_residual_blocks // 2):\n",
        "                h = nn.residual_block(h, gs.pop())\n",
        "                hs.append(h)\n",
        "            if l < n_latent_scales:\n",
        "                ## posterior parameters\n",
        "                q = latent_parameters(h)\n",
        "                qs.append(q)\n",
        "                ## posterior sample\n",
        "                z = latent_sample(q)\n",
        "                zs.append(z)\n",
        "                ## sample feedback\n",
        "                for i in range(n_residual_blocks // 2):\n",
        "                    gz = tf.concat([gs.pop(), z], axis = -1)\n",
        "                    h = nn.residual_block(h, gz)\n",
        "                    hs.append(h)\n",
        "            else:\n",
        "                break\n",
        "            # prepare input to next level\n",
        "            if l + 1 < n_scales:\n",
        "                n_filters = gs[-1].shape.as_list()[-1]\n",
        "                h = nn.upsample(h, n_filters)\n",
        "\n",
        "        return hs, qs, zs\n",
        "\n",
        "\n",
        "def dec_parameters(\n",
        "        h, init = False, **kwargs):\n",
        "    with model_arg_scope(init = init):\n",
        "        num_filters = 3\n",
        "        return nn.conv2d(h, num_filters)\n",
        "\n",
        "\n",
        "def latent_parameters(\n",
        "        h, init = False, **kwargs):\n",
        "    num_filters = kwargs.get(\"num_filters\", h.shape.as_list()[-1])\n",
        "    return nn.conv2d(h, num_filters)\n",
        "\n",
        "\n",
        "def latent_sample(p):\n",
        "    mean = p\n",
        "    stddev = 1.0\n",
        "    eps = tf.random_normal(mean.shape, mean = 0.0, stddev = 1.0)\n",
        "    return mean + stddev * eps\n",
        "\n",
        "\n",
        "def latent_kl(q, p):\n",
        "    mean1 = q\n",
        "    mean2 = p\n",
        "\n",
        "    kl = 0.5 * tf.square(mean2 - mean1)\n",
        "    kl = tf.reduce_sum(kl, axis = [1,2,3])\n",
        "    kl = tf.reduce_mean(kl)\n",
        "    return kl\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}